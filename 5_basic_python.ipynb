{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Um estudo de caso utilizando aprendizado supervisionado: Iris dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importando dados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro é necessário importar algumas bibliotecas. Importaremos as bibliotecas pandas (para trabalhar com Data Frame), numpy (para trabalhar com arrays) e matplotlib.pyplot (para fazer alguns gráficos. Utilizaremos as respectivas abreviações, pd, np e plt. Todas essas bibliotecas são muito importantes e devem ser estudadas frequentemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# utilizaremos o ggplot para melhores gráficos\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca sklearn já possui alguns conjuntos de dados. Importaremos o conjunto de dados Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importando datasets\n",
    "from sklearn import datasets\n",
    "# carregando iris dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber quais atributos do objeto iris, usamos o métodos keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# atributos de um dataset\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploraremos cada um desses atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vejamos o tipo do objeto iris.data\n",
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# as dimensões do objeto iris.data\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A descrição do dataset\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que o dataset tem 4 features e 150 amostras de espécies da flor Iris. As espécies estão divididas em 3 classes, iris-setora, iris-versicolor e iris-virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quais o nome das features\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar os métodos associados ao objeto DataFrame da biblioteca pandas, faz-se necessário transformar o dataset em um objeto do tipo DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# criando iris DataFrame\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['Species'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Explorando os dados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante a análise exploratória do dataset antes de começar a criar modelos que descrevem padrões sobre as features e o target. Utilizaremos agora alguns métodos comuns de exploração de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estatísticas básicas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os valores de máximos e mínimos para as features estão dentro do real, em outras palavras, não há outliers. No entanto, ainda será necessário normalizar os dados durante o preprocessamento por se tratarem de features com características bem distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que não há entradas nulas no dataset. Isso nos poupará algum tempo no preprocessamento. Alguns gráficos podem nos fornecer maiores informações sobre as relações entre as features. Utilizaremos a biblioteca seaborn para criar gráficos mais estilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Escolhendo as cores\n",
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "# criando gráfico para visualização de relações de 2 a 2 features\n",
    "sns.pairplot(df, hue='Species', palette=flatui, vars = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
    "       'petal width (cm)'], size=3,diag_kind=\"hist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explorando correlações com seaborn\n",
    "import seaborn as sns\n",
    "sns.heatmap(df.corr(), square=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir o próximo gráfico utilizaremos diversos métodos. Não se preocupe em entender tudo rapidamente. Tente estudar comando por comando até ter uma visão completa do que foi feito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filtrando por setosas\n",
    "setosa = df[df['Species']==0] \n",
    "# filtrando por versicolors\n",
    "versicolor = df[df['Species']==1] \n",
    "# filtrando por virginica\n",
    "virginica = df[df['Species']==2]\n",
    "# extraindo os valores de comprimento e largura do talo de cada uma das espécies\n",
    "setosa_len = setosa['sepal length (cm)'].values\n",
    "setosa_wid = setosa['sepal width (cm)'].values\n",
    "versicolor_len = versicolor['sepal length (cm)'].values\n",
    "versicolor_wid = versicolor['sepal width (cm)'].values\n",
    "virginica_len = virginica['sepal length (cm)'].values\n",
    "virginica_wid = virginica['sepal width (cm)'].values\n",
    "# plotando comprimento x largura do talo das setosas (em vermelho)\n",
    "plt.scatter(setosa_len,setosa_wid,color='red',label='setosa')\n",
    "# plotando comprimento x largura do talo das versicolors (em azul)\n",
    "plt.scatter(versicolor_len,versicolor_wid,color='blue',label='versicolor')\n",
    "# plotando comprimento x largura do talo das virginicas (em verde)\n",
    "plt.scatter(virginica_len,virginica_wid,color='green',label='virginica')\n",
    "# posicionando a legenda no canto superior direito\n",
    "plt.legend(loc='upper right')\n",
    "# colocando o título\n",
    "plt.title('Iris data')\n",
    "# rotulando o eixo x\n",
    "plt.xlabel('Sepal length (cm)')\n",
    "# rotulando o eixo y\n",
    "plt.ylabel('Sepal width (cm)')\n",
    "# colocando algumas anotações em pontos específicos (xy)\n",
    "plt.annotate('setosa',xy=(5.0,3.5))\n",
    "plt.annotate('virginica',xy=(7.25,3.5))\n",
    "plt.annotate('versicolor',xy=(5.0,2.0))\n",
    "# mostrando o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessamento</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No preprocessamento preparamos os dados para serem ajustados aos modelos. Algumas técnicas são muito comuns nesse estágio. Porém, como o dataset iris já está praticamente pronto, faltando apenas a normalização, apenas mencionaremos algumas das técnicas mais comuns sem aplicá-las.\n",
    "<ul>\n",
    "    <li> Tratamento de dados perdidos </li>\n",
    "    <li> Redução de dimensionalidade </li>\n",
    "    <li> Discretização de features categóricas </li>\n",
    "    <li> Tratamento de outliers </li>\n",
    "    <li> Escolha das features </li>\n",
    "    <li> Normalização dos dados </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalizando\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modelagem</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos criar um modelo de várias formas. Todo o processo é bem parecido. Para ilustrar o processo, utilizaremos o KNeighborsClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importa o modelo\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# cria o modelo (escolhemos o parâmetro n_neighbors=6)\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "# ajustamos o modelo aos dados\n",
    "knn.fit(X, y)\n",
    "# avaliamos o quanto o modelo representa os dados\n",
    "knn.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os passos acima resumem o processo de modelagem. No entanto, para melhores resultados, devemos ser mais metodológicos em cada uma das etapas do processo. Mas, por agora, para se ter uma visão geral, vejamos quais foram os passos:\n",
    "<ol>\n",
    "    <li> Importar o modelo </li>\n",
    "    <li> Escolher os parâmetros </li>\n",
    "    <li> Criar o modelo </li>\n",
    "    <li> Ajustar o modelo aos dados </li>\n",
    "    <li> Avaliar o modelo </li>\n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importando o modelo</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem vários modelos de machine learning na literatura e a biblioteca sklearn possui vários desses. Nosso problema aqui é classificar as espécies de iris dado suas características. Para isso dispomos de um conjunto de 150 amostras já classificadas. Isso é um típico problema de classificação com aprendizado supervisionado. Um dos modelos mais famosos para esse problema é o knn. Existem outros modelos como o Extra trees, Random Forest, Gradient Boosting, etc (experimente usar alguns desses). Para esse tutorial, escolhemos o knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Escolhendo os parâmetros do modelo </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os modelos possuem vários parâmetros e já com seus valores default. No entanto, escolher parâmetros certos aumenta a precisão de seus modelos. Para isso é usado uma técnica chamada de tunagem de hiperparâmetros. Essa técnica consiste em testar vários parâmetros até obter o melhor modelo. No entanto, seu modelo obter uma precisão muito alta em relação ao seu conjunto de dados, não significa que ele é bom. Para ser bom, ele tem que obter uma precisão alta em dados diferentes daqueles usados para a tunagem dos hiperparâmetros. Logo, usaremos uma parte dos dados (traning set) para treinar o modelo e outra parte (test set) para testar nosso modelo. Vejamos como podemos fazer isso com a biblioteca sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=21,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos o X_train e y_train para treinar nosso modelo e o X_test e y_test para testá-lo. Para escolher os parâmetros melhores (tunagem de hiperparâmetros) usaremos uma ferramenta chamada GridSearch, também encontrada na biblioteca sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importando GridSeachCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# criando a grade\n",
    "param_grid = {'n_neighbors':np.arange(1,50)}\n",
    "# criando o modelo default\n",
    "knn = KNeighborsClassifier()\n",
    "# criando o modelo a ser tunado\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv=5)\n",
    "# tunando\n",
    "knn_cv.fit(X_train,y_train)\n",
    "# mostrando os melhoes parâmetros e o melhor score\n",
    "knn_cv.best_params_, knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa tunagem testou todos os modelos knn com o parâmetro 'n_neighbors' variando de 1 a 50. Dentre todos esses, o que obteve melhor precisão (avaliada via validação cruzada com k=5) foi aquele no qual n_neighbors=5. O score máximo obtido foi de 96,19% de acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Criando o modelo</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente, o melhor \"chute\" para ter um knn com alta precisão é escolher o parâmetro n_neighbors=5. Vejamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# criando o modelo com parâmetros tunados\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# ajustando o modelo aos conjunto de treino\n",
    "knn.fit(X_train,y_train)\n",
    "# gerando as classificações para o conjunto de test\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Avaliando o Modelo</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem várias métricas para avaliar o quanto seu modelo é bom. Veremos aqui algumas delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testar o modelo no test\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A métrica acima consiste em pegar as classificações obtidas através do modelo e comparará-las às classificações reais. Não se recomenda utilizar esse processo. O processo mais utilizado é a matriz de confusão e as métricas associadas a esta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Confusion Matrix</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de confusão é uma tabela onde consta o número de classsificações falsas positvas, faltas negativas, verdadeiras positivas e verdadeiras negativas para cada classe envolvendo o problema. Um exmeplo de matriz de confusão para duas classes é ilustrado pela tablea abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>True positive (tp)</td>\n",
    "        <td>False negative (fn)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>False positive (fp)</td>\n",
    "        <td>True negative (tn)</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas métricas associadas a matriz de confusão são:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy:}\\ \\frac{tp + tn}{tp + tn + fp + fn}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Precision:}\\ \\frac{tp}{tp + fp}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Recall:}\\ \\frac{tp}{tp + fn}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{F1-score:}\\ \\  2 * \\frac{Precision * Recall}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mais métricas e maiores informações sobre matriz de confusão clique <a href='https://en.wikipedia.org/wiki/Confusion_matrix'>aqui</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# utilizando matriz de confusão e métricas associadas\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das setosas, o modelo knn treinado acertou 15 de 15 (true positive). Das versicolors, das 15, o modelo acertou 14. A versicolor que foi classificada incorretamente, foi classificada como virginica. Das virginicas, 2 das 15 foram classificadas como versicolors. As outras 13 foram classificadas corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# métricas advindas da matriz de confusão\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Random forest, uma degustação</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem entrar em detalhes, utilizaremos Random forest no lugar de knn. Tente estudar e indenticar as diferenças e semelhanças com o que foi feito anteriormente. Você pode limpar os outputs e inicar seu kernel desse ponto, uma vez que todas os métodos e bibliotecas serão importados novamente. Bons estudos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'gini', 'max_depth': 2, 'max_features': 2, 'n_estimators': 13},\n",
       " 0.97142857142857142)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importando pandas como pd\n",
    "import pandas as pd\n",
    "# importando numpy como np\n",
    "import numpy as np\n",
    "# importando datasets da biblioteca sklearn\n",
    "from sklearn import datasets\n",
    "# carregando iris dataset\n",
    "iris = datasets.load_iris()\n",
    "# criando iris DataFrame\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['Species'] = y\n",
    "# normalizando df\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "# importando o classificador Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# separando o conjunto de treino e de teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=21,stratify=y)\n",
    "# importando GridSeachCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# criando a grade\n",
    "param_grid = {\n",
    "    'n_estimators':np.arange(10,40),\n",
    "    'max_depth':np.arange(1,10),\n",
    "    'max_features':np.arange(1,4),\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "# criando o modelo default\n",
    "forest = RandomForestClassifier()\n",
    "# criando o modelo a ser tunado\n",
    "forest_cv = GridSearchCV(forest, param_grid, cv=5)\n",
    "# tunando\n",
    "forest_cv.fit(X_train,y_train)\n",
    "# mostrando os melhoes parâmetros e o melhor score\n",
    "forest_cv.best_params_, forest_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  1 14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.93      0.87      0.90        15\n",
      "          2       0.88      0.93      0.90        15\n",
      "\n",
      "avg / total       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# criando o modelo com parâmetros tunados\n",
    "forest = RandomForestClassifier(\n",
    "    criterion='gini', \n",
    "    max_depth=2, \n",
    "    max_features=2, \n",
    "    n_estimators=13\n",
    ")\n",
    "# ajustando o modelo aos conjunto de treino\n",
    "forest.fit(X_train,y_train)\n",
    "# gerando as classificações para o conjunto de test\n",
    "y_pred = forest.predict(X_test)\n",
    "# avaliando o modelo\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# gerando matriz de confusão\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "# gerando métricas associadas\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
